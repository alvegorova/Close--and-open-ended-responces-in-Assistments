rm(list = ls())
install.packages(c("tidyverse", "irr"))
require(ggplot2)
require(dplyr)
require(tidyr)
library(irr)
library(readxl) #for excel

setwd("~/Documents/Data_Analysis/EduAI_class")

#### FULL DATA
full_data <- read.csv("final_ready_for_analysis2.csv")
View(full_data)

###Choose important variables
colnames(full_data)
full_data <- full_data %>% dplyr::select (assignment_log_id, assignment_xid, user_xid, 
                                      prior_subparts_count, prior_subparts_avg_score_avg, 
                                      prior_knowledge_continuous, ans_body_clean2, ans_body_length)

###Descriptive statistics

#Full dataset
hist(full_data$prior_subparts_avg_score_avg) #Variable "Success in subparts"
hist(full_data$prior_knowledge_continuous) #Variable "Prior knowledge"

#Creating dataset without 0 in variables
data_without_0 <- full_data %>% 
  filter (prior_subparts_avg_score_avg>0) %>%
  filter (prior_knowledge_continuous>0)

#Distribution of variables "Success in subparts" and "Prior knowledge"
hist(data_without_0$prior_subparts_avg_score_avg) #Variable "Success in subparts"
hist(data_without_0$prior_knowledge_continuous) #Variable "Prior knowledge"

#Relationships between variables "Success in subparts questions" and "Prior knowledge"
plot(data_without_0$prior_knowledge_continuous, data_without_0$prior_subparts_avg_score_avg)
cor.test(data_without_0$prior_knowledge_continuous, data_without_0$prior_subparts_avg_score_avg)

#Data with success lower than 0.5 in subparts questions
data_av_score_less_05 <- data_without_0 %>% filter (prior_subparts_avg_score_avg %in% c(0.1, 0.2, 0.3, 0.4))
sum(data_av_score_less_05$ans_body_clean2 !="")

#### OUR DATASET
dataset <- read_excel("~/Documents/Data_Analysis/EduAI_class/survey_questions_dataset_v6.1.2.xlsx")
View(dataset)
str(dataset)

###Choose important variables
colnames(dataset)
names(dataset)[names(dataset) == '3rd_rater_engaged'] <- 'rater_3_engagement'
dataset <- dataset %>% dplyr::select (assignment_log_id, assignment_xid, user_xid, 
                                      prior_subparts_count, prior_subparts_avg_score_avg, 
                                      prior_knowledge_continuous, ans_body_clean2, ans_body_length, ans_body_word_count,
                                      Question_in_survey, rater_1_engagement, rater_2_engagement, rater_3_engagement, rater_1_challenge, rater_2_challenge)

###Counting variable of "Engagement"
dataset <- dataset %>% mutate (engagement = ifelse(rater_1_engagement == rater_2_engagement, 
                                        rater_2_engagement, rater_3_engagement))
str(dataset)
dataset$engagement <- as.numeric(dataset$engagement)

###Descriptive stats

#Variable "Success in subparts"
hist (dataset$prior_subparts_avg_score_avg)
shapiro.test (dataset$prior_subparts_avg_score_avg) #check normality
qqnorm(dataset$prior_subparts_avg_score_avg, main="")
qqline(dataset$prior_subparts_avg_score_avg, col=2)

#Variable "Prior knowledge"
hist (dataset$prior_knowledge_continuous)
shapiro.test (dataset$prior_knowledge_continuous) #check normality
qqnorm(dataset$prior_knowledge_continuous, main="")
qqline(dataset$prior_knowledge_continuous, col=2)

#Relationships between variables "Success in subparts" and "Prior knowledge"
plot(dataset$prior_knowledge_continuous, dataset$prior_subparts_avg_score_avg)
cor.test(dataset$prior_subparts_avg_score_avg, dataset$prior_knowledge_continuous)

### Inter-rater reliability

##Calculating balance in the rating data (calculate chi square)
table (dataset$rater_1_engagement, dataset$rater_2_engagement) #confusion matrix of graders responses
mean(dataset$rater_1_engagement == 0)
mean(dataset$rater_2_engagement == 0)

##Calculating percent agreement
mean(dataset$rater_1_engagement == dataset$rater_2_engagement)

##Calculating Kappa
kappa2(dataset[,c("rater_1_engagement","rater_2_engagement")], "unweighted")

#Sensitivity_for_not-engaged
mean((dataset$rater_1_engagement == 0) & (dataset$rater_2_engagement == 0))
data_with_rater_1_engagement_0 <- dataset %>% filter(rater_1_engagement == 0)
mean(data_with_julia_0$rater_2_engagement == 0)

#Sensitivity_for_engaged
mean((dataset$rater_1_engagement == 1) & (dataset$rater_2_engagement == 1))
data_with_rater_1_engagement_1 <- dataset %>% filter(rater_1_engagement == 1)
mean(dataset$rater_2_engagement == 1)



#Gwet's Agreement Coefficient 1  (REL package) https://rdrr.io/cran/rel/man/gac.html

###Moderation
#mean centering subparts_score (X) and prior_knowkedge (M)
dataset <- dataset %>% 
  mutate (subparts_score_scaled = scale(prior_subparts_avg_score_avg, center=TRUE, scale=FALSE))
dataset <- dataset %>% 
  mutate (prior_knowledge_scaled = scale(prior_knowledge_continuous, center=TRUE, scale=FALSE))

###Modeling

##Model with one predictor (IV)
fitReg <- glm(formula = engagement ~ subparts_score_scaled, family = "binomial", data = dataset)
summary(fitReg)
#McFadden's Pseudo R^2
fitReg_ll.null <- fitReg$null.deviance/-2
fitReg_ll.proposed <- fitReg$deviance/-2
fitReg_Rsq <- (fitReg_ll.null - fitReg_ll.proposed) / fitReg_ll.null
fitReg_Rsq
#p-value
fitReg_p_value <- 1 - pchisq((fitReg$null.deviance - fitReg$deviance), df=1)
fitReg_p_value

##Model with two predictors (IV and moderator)
fitRegWithM <- glm(formula = engagement ~ subparts_score_scaled + prior_knowledge_scaled, family = "binomial", data = dataset)
summary(fitRegWithM)
#McFadden's Pseudo R^2
fitRegWithM_ll.null <- fitRegWithM$null.deviance/-2
fitRegWithM_ll.proposed <- fitRegWithM$deviance/-2
fitRegWithM_Rsq <- (fitRegWithM_ll.null - fitRegWithM_ll.proposed) / fitRegWithM_ll.null
fitRegWithM_Rsq
#p-value
fitRegWithM_p_value <- 1 - pchisq((fitRegWithM$null.deviance - fitRegWithM$deviance), df=1)
fitRegWithM_p_value

##Model with two predictors and moderation
fitMod <- glm(formula = engagement ~ subparts_score_scaled + prior_knowledge_scaled + subparts_score_scaled * prior_knowledge_scaled, family = "binomial", data = dataset)
summary(fitMod)
#McFadden's Pseudo R^2
fitMod_ll.null <- fitMod$null.deviance/-2
fitMod_ll.proposed <- fitMod$deviance/-2
fitMod_Rsq <- (fitMod_ll.null - fitMod_ll.proposed) / fitMod_ll.null
fitMod_Rsq
#p-value
fitMod_p_value <- 1 - pchisq((fitMod$null.deviance - fitMod$deviance), df=1)
fitMod_p_value

##Difference in R-squared (McFadden's Pseudo R^2)
#Moderation model and model with one predictor
fitMod_Rsq - fitReg_Rsq

#Moderation model and model with two predictors
fitMod_Rsq - fitRegWithM_Rsq

#interaction coefficient (b3) in moderation model
names(summary(fitMod))
coef(summary(fitMod))['subparts_score_scaled:prior_knowledge_scaled',1] #b3
#the same
#coef(fitMod)['subparts_score_scaled:prior_knowledge_scaled']

#p-value of interaction coefficient
coef(summary(fitMod))['subparts_score_scaled:prior_knowledge_scaled',4]

###Using length as a predictor

##Model with answer length (symbols)
fitRegLength1 <- glm(formula = engagement ~ ans_body_length, family = "binomial", data = dataset)
summary(fitRegLength1)
#McFadden's Pseudo R^2
fitRegLength1_ll.null <- fitRegLength1$null.deviance/-2
fitRegLength1_ll.proposed <- fitRegLength1$deviance/-2
fitRegLength1_Rsq <- (fitRegLength1_ll.null - fitRegLength1_ll.proposed) / fitRegLength1_ll.null
fitRegLength1_Rsq
#p-value
fitRegLength1_p_value <- 1 - pchisq((fitRegLength1$null.deviance - fitRegLength1$deviance), df=1)
fitRegLength1_p_value

#plot logistic regression curve
newdata <- data.frame(ans_body_length=seq(min(dataset$ans_body_length), max(dataset$ans_body_length),len=500))
newdata$engagement = predict(fitRegLength1, newdata, type="response")
plot(engagement ~ ans_body_length, data=dataset, col="steelblue")
lines(engagement ~ ans_body_length, data=newdata, lwd=2)

##Model with answer length (word count)
fitRegLength2 <- glm(formula = engagement ~ ans_body_word_count, family = "binomial", data = dataset)
summary(fitRegLength2)
#McFadden's Pseudo R^2
fitRegLength2_ll.null <- fitRegLength2$null.deviance/-2
fitRegLength2_ll.proposed <- fitRegLength2$deviance/-2
fitRegLength2_Rsq <- (fitRegLength2_ll.null - fitRegLength2_ll.proposed) / fitRegLength2_ll.null
fitRegLength2_Rsq
#p-value
fitRegLength2_p_value <- 1 - pchisq((fitRegLength2$null.deviance - fitRegLength2$deviance), df=1)
fitRegLength2_p_value
